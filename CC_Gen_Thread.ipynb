{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import threading\n",
    "from openai import OpenAI\n",
    "import config\n",
    "\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    \"\"\"Reads the content of a given file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return file.read()\n",
    "    except IOError as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def chunk_text(text, max_tokens):\n",
    "    \"\"\"Divides a text into chunks each of which is at most max_tokens long.\"\"\"\n",
    "    chunks = []\n",
    "    while len(text) > max_tokens:\n",
    "        chunk, text = text[:max_tokens], text[max_tokens:]\n",
    "        chunks.append(chunk)\n",
    "    if text:\n",
    "        chunks.append(text)\n",
    "    return chunks\n",
    "\n",
    "def get_user_prompt():\n",
    "    \"\"\"Prompts the user for the input to be processed by OpenAI.\"\"\"\n",
    "    print(\"Please enter the prompt for OpenAI completion:\")\n",
    "    return input()\n",
    "\n",
    "def process_text(client, chunk, prompt):\n",
    "    \"\"\"Processes a chunk of text through the OpenAI API.\"\"\"\n",
    "    try:\n",
    "        full_prompt = prompt.replace(\"content\", chunk)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": full_prompt},\n",
    "            ],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process text: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_file(client, file_path, root_folder, prompt, writer, lock):\n",
    "    \"\"\"Processes a single file and writes the result to the CSV file.\"\"\"\n",
    "    content = read_file_content(file_path)\n",
    "    if content:\n",
    "        relative_path = os.path.relpath(os.path.dirname(file_path), root_folder)\n",
    "        formatted_filename = os.path.join(relative_path, os.path.basename(file_path))\n",
    "\n",
    "        content_chunks = chunk_text(content, 16300)\n",
    "        responses = []\n",
    "        for chunk in content_chunks:\n",
    "            response = process_text(client, chunk, prompt)\n",
    "            if response:\n",
    "                responses.append(response)\n",
    "\n",
    "        combined_response = \"\\n\".join(responses)\n",
    "        \n",
    "        with lock:\n",
    "            writer.writerow({\n",
    "                'filename': formatted_filename,\n",
    "                'file_content': content,\n",
    "                'response': combined_response\n",
    "            })\n",
    "\n",
    "def process_files(root_folder, extensions, output_file, prompt):\n",
    "    \"\"\"Processes files that match given extensions in a directory tree using multithreading.\"\"\"\n",
    "    client = OpenAI(api_key=config.api_key)  # Replace with your actual OpenAI API key\n",
    "    lock = threading.Lock()  # Lock for writing to CSV file\n",
    "\n",
    "    with open(output_file, mode='w', newline='') as csvfile:\n",
    "        fieldnames = ['filename', 'file_content', 'response']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        threads = []\n",
    "\n",
    "        for folder_path, _, filenames in os.walk(root_folder):\n",
    "            for filename in filenames:\n",
    "                if any(filename.endswith(ext) for ext in extensions):\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    thread = threading.Thread(target=process_file, args=(client, file_path, root_folder, prompt, writer, lock))\n",
    "                    threads.append(thread)\n",
    "                    thread.start()\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    root_folder = \"/Users/parthagarwal/Desktop/Allen_12/Biology_all/\"\n",
    "    output_file = \"bio1.csv\"\n",
    "    extensions = [\".txt\", \".mmd\"]\n",
    "    user_prompt = \"Design a series of structured concept cards tailored for NEET preparation, focusing on a specific Biology chapter. Each card should contain 30-35 words and include critical and key Biology concepts essential for the NEET exam. Use content from the provided 'mmd_content' for each card, ensuring it covers all necessary concepts and data from the 'mmd_file'. The layout of the cards should facilitate quick revision, enhance memorization, and aid in understanding, making them highly effective for NEET candidates. Ensure the content is concise, complete, and optimized for quick learning.\"\n",
    "    process_files(root_folder, extensions, output_file, user_prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
