{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.34.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m987.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.18.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, tqdm, sniffio, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.4.0 certifi-2024.6.2 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 openai-1.34.0 pydantic-2.7.4 pydantic-core-2.18.4 sniffio-1.3.1 tqdm-4.66.4 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import threading\n",
    "from openai import OpenAI\n",
    "import config\n",
    "\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    \"\"\"Reads the content of a given file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return file.read()\n",
    "    except IOError as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def chunk_text(text, max_tokens):\n",
    "    \"\"\"Divides a text into chunks each of which is at most max_tokens long.\"\"\"\n",
    "    chunks = []\n",
    "    while len(text) > max_tokens:\n",
    "        chunk, text = text[:max_tokens], text[max_tokens:]\n",
    "        chunks.append(chunk)\n",
    "    if text:\n",
    "        chunks.append(text)\n",
    "    return chunks\n",
    "\n",
    "def get_user_prompt():\n",
    "    \"\"\"Prompts the user for the input to be processed by OpenAI.\"\"\"\n",
    "    print(\"Please enter the prompt for OpenAI completion:\")\n",
    "    return input()\n",
    "\n",
    "def process_text(client, chunk, prompt):\n",
    "    \"\"\"Processes a chunk of text through the OpenAI API.\"\"\"\n",
    "    try:\n",
    "        full_prompt = prompt.replace(\"content\", chunk)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": full_prompt},\n",
    "            ],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process text: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_file(client, file_path, root_folder, prompt, writer, lock):\n",
    "    \"\"\"Processes a single file and writes the result to the CSV file.\"\"\"\n",
    "    content = read_file_content(file_path)\n",
    "    if content:\n",
    "        relative_path = os.path.relpath(os.path.dirname(file_path), root_folder)\n",
    "        formatted_filename = os.path.join(relative_path, os.path.basename(file_path))\n",
    "\n",
    "        content_chunks = chunk_text(content, 16300)\n",
    "        responses = []\n",
    "        for chunk in content_chunks:\n",
    "            response = process_text(client, chunk, prompt)\n",
    "            if response:\n",
    "                responses.append(response)\n",
    "\n",
    "        combined_response = \"\\n\".join(responses)\n",
    "        \n",
    "        with lock:\n",
    "            writer.writerow({\n",
    "                'filename': formatted_filename,\n",
    "                'file_content': content,\n",
    "                'response': combined_response\n",
    "            })\n",
    "\n",
    "def process_files(root_folder, extensions, output_file, prompt):\n",
    "    \"\"\"Processes files that match given extensions in a directory tree using multithreading.\"\"\"\n",
    "    client = OpenAI(api_key=config.api_key)  # Replace with your actual OpenAI API key\n",
    "    lock = threading.Lock()  # Lock for writing to CSV file\n",
    "\n",
    "    with open(output_file, mode='w', newline='') as csvfile:\n",
    "        fieldnames = ['filename', 'file_content', 'response']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        threads = []\n",
    "\n",
    "        for folder_path, _, filenames in os.walk(root_folder):\n",
    "            for filename in filenames:\n",
    "                if any(filename.endswith(ext) for ext in extensions):\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    thread = threading.Thread(target=process_file, args=(client, file_path, root_folder, prompt, writer, lock))\n",
    "                    threads.append(thread)\n",
    "                    thread.start()\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    root_folder = \"/Users/parthagarwal/Desktop/Allen_12/Biology_all/\"\n",
    "    output_file = \"bio1.csv\"\n",
    "    extensions = [\".txt\", \".mmd\"]\n",
    "    user_prompt = \"Design a series of structured concept cards tailored for NEET preparation, focusing on a specific Biology chapter. Each card should contain 30-35 words and include critical and key Biology concepts essential for the NEET exam. Use content from the provided 'mmd_content' for each card, ensuring it covers all necessary concepts and data from the 'mmd_file'. The layout of the cards should facilitate quick revision, enhance memorization, and aid in understanding, making them highly effective for NEET candidates. Ensure the content is concise, complete, and optimized for quick learning.\"\n",
    "    process_files(root_folder, extensions, output_file, user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
